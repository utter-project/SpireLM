import "uservars_tokenizer.tconf"

global {

    ducttape_experimental_imports=true
    ducttape_experimental_submitters=true
    ducttape_experimental_multiproc=true

    n_dsus=5000

    init_strategy="mean"

    # what is this even for?
    fleurs_dsus="/mnt/scratch-artemis/bpop/tower-speech-outputs/asr-outputs/DeduplicateDSUs/ASRDataset.fleurs/labels.km.dedup"

    base_model="Unbabel/TowerBase-7B-v0.1"

    # I would like not to need this
    # how do we easily save the sentencepiece model?
    # tower_base_spm="/mnt/scratch-artemis/bpop/cache/hub/models--Unbabel--TowerBase-7B-v0.1/snapshots/bd59c10d76007e960368acfc15bebc201c112b1b/tokenizer.model"

    # spire_full="/mnt/data-artemis/bpop/tsi-v5-2812"
}
